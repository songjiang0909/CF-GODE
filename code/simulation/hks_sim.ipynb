{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "import Hawkes as hk\n",
    "import numpy as np\n",
    "from scipy.stats import truncnorm\n",
    "from simulation_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_prop = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['health_condition', 'action_dosage', 'avg_neighbor_action_dosage', 'action_application_point', 'treatment_probs'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_health_stage(row):\n",
    "    \"\"\"\n",
    "    > This function takes a list of numbers, converts them to a diameter in centimeters, and then returns a list of\n",
    "    cancer stages\n",
    "\n",
    "    row: the row of the dataframe that we're currently on\n",
    "    return: A list of the cancer stages for each tumor.\n",
    "    \"\"\"\n",
    "# health_stages_stats = {\n",
    "#     \"I\": (1.5, 1, global_min, 3),\n",
    "#     \"II\": (4.5, 1, 3, 6),\n",
    "#     \"III\": (8, 1, 6, global_max),\n",
    "# }\n",
    "    stage_list = []\n",
    "\n",
    "    for idx, number in enumerate(row):\n",
    "\n",
    "        diameter_cm = (number / (math.pi / 6)) ** (1.0 / 3.0)\n",
    "\n",
    "        if number < 3:\n",
    "            stage = 1\n",
    "        elif number >= 3 and number < 6:\n",
    "            stage = 2\n",
    "        elif number >= 6:\n",
    "            stage = 3\n",
    "\n",
    "        stage_list.append(stage)\n",
    "\n",
    "    return stage_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_hawkes(mu, alpha, beta, start, end):\n",
    "    \"\"\"\n",
    "    It simulates a Hawkes process with the given parameters and returns the event times\n",
    "\n",
    "    mu (float): the baseline intensity\n",
    "    alpha (float): the intensity of the process\n",
    "    beta (float): the decay rate of the exponential kernel\n",
    "    start (int): the start time of the simulation\n",
    "    end (int): the end time of the simulation\n",
    "    return: a list of times at which events occur.\n",
    "    \"\"\"\n",
    "    import random\n",
    "\n",
    "    random.seed(30)\n",
    "    model = hk.simulator()\n",
    "    model.set_kernel(\"exp\")\n",
    "    model.set_baseline(\"const\")\n",
    "\n",
    "    para = {\"mu\": mu, \"alpha\": alpha, \"beta\": beta}\n",
    "    model.set_parameter(para)\n",
    "\n",
    "    itv = [start, end]  # the observation interval\n",
    "    T = model.simulate(itv)\n",
    "\n",
    "    T = np.unique([int(x) for x in T])\n",
    "\n",
    "    return T\n",
    "\n",
    "\n",
    "def get_timestamps(states, kappa):\n",
    "    \"\"\"\n",
    "    The function takes in a list of states and a kappa value, and returns a list of timestamps that\n",
    "    are generated using a Hawkes process\n",
    "\n",
    "    states (list): a list of integers, where each integer represents a state\n",
    "    kappa (float): the ratio of the intensity of the next state to the current state\n",
    "    return: A list of timestamps\n",
    "    \"\"\"\n",
    "\n",
    "    # state indices\n",
    "    s1_idx = np.where(np.array(states) == 1)[0]\n",
    "    s2_idx = np.where(np.array(states) == 2)[0]\n",
    "    s3_idx = np.where(np.array(states) == 3)[0]\n",
    "\n",
    "    # apply kappa\n",
    "    mu_s1 = 0.01\n",
    "    mu_s2 = kappa * mu_s1\n",
    "    mu_s3 = kappa * mu_s2\n",
    "\n",
    "    # simulate Hawkes per cancer state\n",
    "    overall_timestamps = []\n",
    "\n",
    "    if len(s3_idx) > 1:\n",
    "        s3_timestamps = simulate_hawkes(\n",
    "            mu=mu_s3,\n",
    "            alpha=0.5,\n",
    "            beta=2,\n",
    "            start=s3_idx[0],\n",
    "            end=s3_idx[-1],\n",
    "        )\n",
    "        overall_timestamps.extend(s3_timestamps)\n",
    "\n",
    "    if len(s2_idx) > 1:\n",
    "        s2_timestamps = simulate_hawkes(\n",
    "            mu=mu_s2,\n",
    "            alpha=0.1,\n",
    "            beta=2,\n",
    "            start=s2_idx[0],\n",
    "            end=s2_idx[-1],\n",
    "        )\n",
    "        overall_timestamps.extend(s2_timestamps)\n",
    "\n",
    "    if len(s1_idx) > 1:\n",
    "        s1_timestamps = simulate_hawkes(\n",
    "            mu=mu_s1,\n",
    "            alpha=0.01,\n",
    "            beta=2,\n",
    "            start=s1_idx[0],\n",
    "            end=s1_idx[-1],\n",
    "        )\n",
    "        overall_timestamps.extend(s1_timestamps)\n",
    "\n",
    "    return overall_timestamps\n",
    "\n",
    "\n",
    "def sim_hawkes(states, kappa):\n",
    "    \"\"\"\n",
    "    > This function simulates a Hawkes process with the given states and kappa\n",
    "\n",
    "    states (list): a list of lists, where each list is a list of timestamps for a particular state\n",
    "    kappa (float): the intensity of the hawkes process\n",
    "    return: The timestamps of the events.\n",
    "    \"\"\"\n",
    "\n",
    "    done = False\n",
    "    i = 0\n",
    "    while done == False:\n",
    "        overall_timestamps = get_timestamps(states, kappa)\n",
    "\n",
    "        t_len = len(overall_timestamps)\n",
    "        state_len = len(states)\n",
    "\n",
    "        # if t_len>0.1*state_len:\n",
    "        done = True\n",
    "\n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break\n",
    "\n",
    "    return overall_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_sample:1591\n",
      "sample_prop:1\n",
      "0 : Running - Hawkes\n",
      "100 : Running - Hawkes\n",
      "200 : Running - Hawkes\n",
      "300 : Running - Hawkes\n",
      "400 : Running - Hawkes\n",
      "500 : Running - Hawkes\n",
      "600 : Running - Hawkes\n",
      "700 : Running - Hawkes\n",
      "800 : Running - Hawkes\n",
      "900 : Running - Hawkes\n",
      "1000 : Running - Hawkes\n",
      "1100 : Running - Hawkes\n",
      "1200 : Running - Hawkes\n",
      "1300 : Running - Hawkes\n",
      "1400 : Running - Hawkes\n",
      "1500 : Running - Hawkes\n"
     ]
    }
   ],
   "source": [
    "dataset = \"Flickr\"\n",
    "data = load_sim(dataset)\n",
    "\n",
    "raw_data = deepcopy(data) ##to change\n",
    "total_samples = raw_data[\"health_condition\"].shape[0]\n",
    "print (\"total_sample:{}\".format(total_samples))\n",
    "print (\"sample_prop:{}\".format(sample_prop))\n",
    "samples = int(total_samples * sample_prop)\n",
    "random.seed(int(80))\n",
    "sample_idxs = random.sample(range(0, total_samples), samples)\n",
    "for feature in raw_data.keys():\n",
    "    try:\n",
    "        raw_data[feature] = raw_data[feature][sample_idxs]\n",
    "    except:\n",
    "        continue\n",
    "health_condition = raw_data[\"health_condition\"]\n",
    "\n",
    "health_stages = np.apply_along_axis(convert_to_health_stage, 0, health_condition)\n",
    "features = list(raw_data.keys())\n",
    "\n",
    "\n",
    "for idx, indiv_stage in enumerate(health_stages):\n",
    "    if np.sum(raw_data[\"action_application_point\"][idx]) <= 2:\n",
    "        untreated = True\n",
    "        treated = False\n",
    "        kappa = 1\n",
    "    else:\n",
    "        untreated = False\n",
    "        treated = True\n",
    "        kappa = 10\n",
    "\n",
    "    if idx % 100 == 0:\n",
    "        print(idx, \": Running - Hawkes\")\n",
    "\n",
    "    final_hawkes = []\n",
    "    for i in range(5):\n",
    "        final_hawkes.extend(sim_hawkes(indiv_stage, kappa))\n",
    "    final_sampled_indices = np.unique(final_hawkes)\n",
    "\n",
    "    for feature in features:'health_condition', 'action_dosage', 'avg_neighbor_action_dosage', 'action_application_point', 'treatment_probs'\n",
    "            if feature in [\n",
    "                \"health_condition\",\n",
    "                \"action_dosage\",\n",
    "                \"avg_neighbor_action_dosage\",\n",
    "                \"action_application_point\",\n",
    "                \"treatment_probs\"\n",
    "            ]:\n",
    "                mask_vec = masked_vector(\n",
    "                    input_vector=raw_data[feature][idx],\n",
    "                    mask_indices=final_sampled_indices,\n",
    "                    mask_type=0,\n",
    "                )\n",
    "                if interpolate == True:\n",
    "                    mask_vec = np.array(mask_vec, dtype=np.float64)\n",
    "                    nans, x = nan_helper(mask_vec)\n",
    "                    mask_vec[nans] = np.interp(x(nans), x(~nans), mask_vec[~nans])\n",
    "\n",
    "                raw_data[feature][idx] = mask_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_sampler(\n",
    "    data,\n",
    "    data_split,\n",
    "    interpolate=False,\n",
    "    strategy=\"all\",\n",
    "    sample_prop=1,\n",
    "    kappa=10,\n",
    "    max_samples=5000,\n",
    "):\n",
    "\n",
    "    \"\"\"\n",
    "    > This function takes in a data dictionary, a data split, and a few other parameters, and returns a\n",
    "    data dictionary with the same keys as the input data dictionary, but with the values sampled\n",
    "    according to the Hawkes process.\n",
    "\n",
    "    The function first creates a copy of the data dictionary, and then samples the data according to the\n",
    "    number of samples specified by the user.\n",
    "\n",
    "    It then iterates through each sample, and determines whether the sample is treated or\n",
    "    untreated. If the sample is untreated, the function uses a Hawkes process with a kappa value of 1.\n",
    "    If the sample is treated, the function uses a Hawkes process with a kappa value of 10.\n",
    "\n",
    "    It then uses the Hawkes process to generate a list of indices, and then uses these indices\n",
    "    to mask the data.\n",
    "\n",
    "    Finally, it then returns the data dictionary with the masked data.\n",
    "\n",
    "    data: the data dictionary\n",
    "    data_split: The data split you want to sample from\n",
    "    interpolate: If True, interpolates the missing values in the data, defaults to False\n",
    "    (optional)\n",
    "    strategy: \"all\" or \"random\", defaults to all (optional)\n",
    "    sample_prop: The proportion of the data to sample, defaults to 1 (optional)\n",
    "    kappa: the intensity of the hawkes process, defaults to 10 (optional)\n",
    "    max_samples: The maximum number of samples to be taken from the data, defaults to 5000\n",
    "    (optional)\n",
    "    \"\"\"\n",
    "\n",
    "    def nan_helper(y):\n",
    "        return np.isnan(y), lambda z: z.nonzero()[0]\n",
    "\n",
    "    raw_data = deepcopy(data[data_split])\n",
    "    total_samples = raw_data[\"cancer_volume\"].shape[0]\n",
    "    print (\"total_sample:{}\".format(total_samples))\n",
    "    print (\"sample_prop:{}\".format(sample_prop))\n",
    "    samples = int(total_samples * sample_prop)\n",
    "\n",
    "    if \"validation\" in data_split:\n",
    "        samples = 1000\n",
    "    if samples > 10000:\n",
    "        samples = 10000\n",
    "\n",
    "    print(f\"{samples}: samples\")\n",
    "\n",
    "    random.seed(int(80))\n",
    "    sample_idxs = random.sample(range(0, total_samples), samples)\n",
    "\n",
    "    for feature in raw_data.keys():\n",
    "        try:\n",
    "            raw_data[feature] = raw_data[feature][sample_idxs]\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    cancer_volume = raw_data[\"cancer_volume\"]\n",
    "\n",
    "    cancer_stages = np.apply_along_axis(convert_to_cancer_stage, 0, cancer_volume)\n",
    "    features = list(raw_data.keys())\n",
    "\n",
    "    for idx, indiv_stage in enumerate(cancer_stages):\n",
    "        if np.sum(raw_data[\"radio_application\"][idx]) <= 2 and np.sum(\n",
    "            raw_data[\"chemo_application\"][idx] <= 2,\n",
    "        ):\n",
    "            untreated = True\n",
    "            treated = False\n",
    "            kappa = 1\n",
    "        else:\n",
    "            untreated = False\n",
    "            treated = True\n",
    "            kappa = 10\n",
    "\n",
    "        if idx % 100 == 0:\n",
    "            print(idx, \": Running - Hawkes\")\n",
    "\n",
    "        final_hawkes = []\n",
    "        for i in range(5):\n",
    "            final_hawkes.extend(sim_hawkes(indiv_stage, kappa))\n",
    "        final_sampled_indices = np.unique(final_hawkes)\n",
    "\n",
    "\n",
    "        for feature in features:\n",
    "            if feature in [\n",
    "                \"cancer_volume\",\n",
    "                \"chemo_dosage\",\n",
    "                \"radio_dosage\",\n",
    "                \"chemo_application\",\n",
    "                \"radio_application\",\n",
    "                \"chemo_probabilities\",\n",
    "                \"radio_probabilities\",\n",
    "            ]:\n",
    "                mask_vec = masked_vector(\n",
    "                    input_vector=raw_data[feature][idx],\n",
    "                    mask_indices=final_sampled_indices,\n",
    "                    mask_type=0,\n",
    "                )\n",
    "                if interpolate == True:\n",
    "                    mask_vec = np.array(mask_vec, dtype=np.float64)\n",
    "                    nans, x = nan_helper(mask_vec)\n",
    "                    mask_vec[nans] = np.interp(x(nans), x(~nans), mask_vec[~nans])\n",
    "\n",
    "                raw_data[feature][idx] = mask_vec\n",
    "\n",
    "    raw_data[\"intensity\"] = np.apply_along_axis(\n",
    "        get_intensity_vector,\n",
    "        1,\n",
    "        raw_data[\"cancer_volume\"],\n",
    "    )\n",
    "\n",
    "    return raw_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causalode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:31:59) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5961c4cae96f02aeefc5ef61cf19ad4f8eaf1340ef18140b255d136d19063efa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
